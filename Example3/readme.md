Example2
======================
  本例实现交叉熵损失函数， 
  通过自己构建均方差损失函数和随机梯度下降来优化模型参数。
  
  数据集按照下面标准进行生成：

  |   | x0        | x1        | x2        | x3      |
  |---|-----------|-----------|-----------|---------|
  | 0 | 200 - 300 | 0.6 - 1.0 | 0.7 - 1.2 | 8 - 12  |
  | 1 | 150 - 250 | 0.4 - 0.6 | 0.3 - 0.5 | 13 - 16 |
  | 2 | 100 - 200 | 0.3 - 0.5 | 0.6 - 0.9 | 4 - 7   |

  并有1%的概率生成错误的label。
  label不是独立热编码，而是一个数字：0, 1, 2
  实际上，本例仍有考虑不足的地方，比如一个物体它可能完全不属于这三个类别中的任何一个，
  不过要做到也并不难，就相当于增添一个类别，表示它不是这三个类别的概率
  
  为了让读者更加熟悉深度神经网络的训练流程，本例特别将pytorch中的常用接口按照
  自己的方式实现并使用。但请注意，这并非pytorch的源码，甚至和源码有很大的出入，
  请不要误解。
  
  本例的重点在softmax函数和交叉熵函数上。

